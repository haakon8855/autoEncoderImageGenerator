"""haakon8855"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow import keras as ks

from auto_encoder import AutoEncoder
from var_auto_encoder import VariationalAutoEncoder
from verification_net import VerificationNet
from stacked_mnist import StackedMNISTData, DataMode


class DeepGenerativeModel:
    """
    Run the deep generative model
    """

    def __init__(self, use_vae=False):
        self.use_vae = use_vae
        self.latent_dim = 5
        self.epochs = 30
        self.image_size = 28
        self.retrain = False
        self.run_anomaly_detection = False
        self.batch_size = 1024
        # Anomaly detection
        self.check_for_anomalies = 1000
        self.k_anomalies = 15
        # Reconstruction display
        self.number_of_reconstructions = 20
        self.display_offset = 60
        # Generative model
        self.number_to_generate = 400
        self.generated_to_display = 20

        model_identifier = "ae"
        if use_vae:
            model_identifier = "vae"
        self.ae_weights_file_name = f"./model_{model_identifier}_std/verification_model"
        if self.run_anomaly_detection:
            self.ae_weights_file_name = f"./model_{model_identifier}_anom/verification_model"
        if use_vae:
            self.auto_encoder = VariationalAutoEncoder(self.latent_dim,
                                                       self.image_size,
                                                       retrain=True)
        else:
            self.auto_encoder = AutoEncoder(self.latent_dim,
                                            self.image_size,
                                            retrain=self.retrain)

        self.verification_net = None
        self.init_verification_net()

    def init_verification_net(self):
        """
        Train the verification net (will use stored weights as long as
        force_learn=False)
        """
        gen = StackedMNISTData(mode=DataMode.MONO_BINARY_COMPLETE,
                               default_batch_size=2048)
        self.verification_net = VerificationNet(force_learn=False)
        self.verification_net.train(generator=gen, epochs=5)

    def init_auto_encoder(self):
        """
        Initializes the auto encoder, either an AE or a VAE.
        """
        if self.use_vae:
            # TODO: Config? What is this number?
            optimizer = ks.optimizers.Adam(1e-4)
            self.auto_encoder.set_optimizer(optimizer)
            # TODO: What else, train or smth, idk...
        else:
            self.auto_encoder.compile(
                optimizer='adam',
                loss=ks.losses.BinaryCrossentropy(),
            )

    def display_generated(self, images, amount_to_display):
        """
        Display the images generated by the generative model.
        """
        plt.figure(figsize=(amount_to_display, 4))
        for i in range(amount_to_display):
            # Display generative
            ax = plt.subplot(2, amount_to_display, i + 1 + amount_to_display)
            plt.imshow(images[i])
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
        plt.show()

    def display_anomalies(self, k, x_test, x_pred, loss):
        """
        Display the k most anomalous image reconstructions found in
        the test set.
        """
        largest_loss = np.argpartition(loss, -k)[-k:]
        plt.figure(figsize=(k, k))
        for i in range(k):
            # Display original
            ax = plt.subplot(2, k, i + 1)
            plt.imshow(x_test[largest_loss[i]])
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
            # Display most loss
            ax = plt.subplot(2, k, i + k + 1)
            plt.imshow(x_pred[largest_loss[i]])
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
        plt.show()

    def display_reconstructions(self, x_test, x_pred, n=20, offset=0):
        """
        Display n original images along with their reconstruction by the AE
        """
        plt.figure(figsize=(20, 4))
        for i in range(n):
            # Display original
            ax = plt.subplot(2, n, i + 1)
            plt.imshow(x_test[i + offset])
            plt.title(i + 1)
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
            # Display reconstruction
            ax = plt.subplot(2, n, i + 1 + n)
            plt.imshow(x_pred[i + offset])
            plt.title(i + 1)
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
        plt.show()

    def detect_anomalies(self):
        """
        Runs anomaly detection.
        """
        gen_test = StackedMNISTData(mode=DataMode.MONO_BINARY_COMPLETE,
                                    default_batch_size=2048)

        # Fetch complete test data set
        x_test, _ = gen_test.get_full_data_set(training=False)
        # Only look at one channel:
        x_test = x_test[:, :, :, [0]]

        decoded_imgs = self.call(x_test)

        print("Checking for anomalies")
        loss = self.auto_encoder.measure_loss(
            x_test, decoded_imgs, check_range=self.check_for_anomalies)
        # Display the k_anomalies images with the most loss for
        # first 'check_for_anomalies' (e.g. 1000) samples of test set.
        self.display_anomalies(self.k_anomalies, x_test, decoded_imgs, loss)
        return decoded_imgs

    def generate_images(self):
        """
        Generate random vectors in the latent vector-space
        and feed them through the decoder.
        """
        generated = self.auto_encoder.generate_images(self.number_to_generate)
        self.display_generated(generated, self.generated_to_display)
        return generated

    def call(self, x_test):
        """
        Run images through encoder and decoder
        """
        encoded_imgs = self.auto_encoder.encoder(x_test).numpy()
        decoded_imgs = self.auto_encoder.decoder(encoded_imgs).numpy()
        return decoded_imgs

    def run(self):
        """
        Runs the auto encoder.
        """
        # Set up data set generators/fetchers
        data_mode = DataMode.MONO_BINARY_COMPLETE
        if self.run_anomaly_detection:
            data_mode = DataMode.MONO_BINARY_MISSING
        gen_train = StackedMNISTData(mode=data_mode, default_batch_size=2048)
        gen_test = StackedMNISTData(mode=data_mode, default_batch_size=2048)

        # Fetch training and test data sets
        x_train, _ = gen_train.get_full_data_set(training=True)
        x_test, y_test = gen_test.get_full_data_set(training=False)
        # Only look at one channel:
        x_train = x_train[:, :, :, [0]]
        x_test = x_test[:, :, :, [0]]

        self.init_auto_encoder()
        # Train the network using the training data set and predefined parameters
        print("Training network")
        self.auto_encoder.train(x_train,
                                epochs=self.epochs,
                                batch_size=self.batch_size,
                                shuffle=True,
                                validation_data=(x_test, x_test))

        if self.run_anomaly_detection:
            decoded_imgs = self.detect_anomalies()
            return

        decoded_imgs = self.call(x_test)
        print(y_test[self.display_offset:self.number_of_reconstructions +
                     self.display_offset])
        self.display_reconstructions(x_test, decoded_imgs,
                                     self.number_of_reconstructions,
                                     self.display_offset)

        # VERIFICATION
        # Send reconstructed images through the verification net,
        # check coverage, predictability and accuracy for the reconstructed
        # original images.
        reconstructed = decoded_imgs[:, :, :, np.newaxis]
        cov = self.verification_net.check_class_coverage(reconstructed)
        pred, acc = self.verification_net.check_predictability(
            reconstructed, y_test)
        print(f"Coverage: {100*cov:.2f}%")
        print(f"Predictability: {100*pred:.2f}%")
        print(f"Accuracy: {100 * acc:.2f}%")

        generated_imgs = self.generate_images()[:, :, :, np.newaxis]
        # gen_cov = self.verification_net
        gen_cov = self.verification_net.check_class_coverage(generated_imgs)
        gen_pred, _ = self.verification_net.check_predictability(
            generated_imgs)
        print(f"Generated imgs coverage: {100*gen_cov:.2f}%")
        print(f"Generated imgs predictability: {100*gen_pred:.2f}%")


def main():
    """
    Main method for running the deep generative model.
    """
    dgm = DeepGenerativeModel(use_vae=True)
    dgm.run()


if __name__ == "__main__":
    main()